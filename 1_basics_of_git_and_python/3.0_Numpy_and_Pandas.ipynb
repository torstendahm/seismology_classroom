{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy and Pandas\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Numpy and Pandas are Python libraries that support data manipulation. \n",
    "\n",
    "* **NumPy** library adds support for large, multi-dimensional arrays and matrices together with a large collection of high-level mathematical functions that can be used on these arrays. The advantage of using NumPy is that it consumes less memory to store the data and it allows to specify the data types, making the code more optimized.    To install it check [NumPy-installation](https://numpy.org/install/).\n",
    "\n",
    "\n",
    "* **Pandas** is built on NumPy and it is a high-level data manipulation tool. It offers data and operations structures to manipulate numerical tables and time series. In Pandas, the data structure is called DataFrame and it allows to store and manipulate tabular data with rows and columns. To install it check [Pandas-installation](https://pandas.pydata.org/getting_started.html).\n",
    "\n",
    "**Table of contents:**\n",
    "\n",
    "* [Libraries import](#Libraries-import)\n",
    "* [Basics of Numpy](#Basics-of-NumPy)\n",
    "* [Reading files with NumPy](#Reading-files-with-NumPy)\n",
    "* [Basics of Pandas](#Basics-of-Pandas)\n",
    "* [Reading files with Pandas](#Reading-files-with-Pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries import\n",
    "\n",
    "Libraries are very simple to import, as this is done exactly like modules. It is very common to see both libraries imported with a shortened name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of NumPy\n",
    "\n",
    "As mentioned before, NumPy has included a big amount of mathematical functions and methods. In [NumPy routines](https://numpy.org/doc/stable/reference/routines.html) you can take a look at all the routines available in NumPy. For example, if we want to calculate the square root of a value, we can simply do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could perform a calculation over many values. Let's use `numpy.linspace` to create a sequence of values evenly spaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(1,10,5) # Sequence starts at 1, ends at 10, and has 5 evenly spaced samples.\n",
    "\n",
    "print(np.sin(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NumPy, the data structure is the **array**. An array is a very powerful data structure as we can perform calculations directly on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_values = [3.8, 4.5, 6.2, 3.7, 5.2, 7.1] \n",
    "corrections_list = [0.8, 0.9, 0.95, 0.87, 0.6, 0.94]\n",
    "\n",
    "# We redefine each list as an array. (We can also use the same name and the variable will be overwritten)\n",
    "values = np.array(list_of_values)\n",
    "corrections = np.array(corrections_list)\n",
    "print('The values array is:', values)\n",
    "print('The corrections array is:', corrections)\n",
    "#Now we can perform operations directly on the arrays instead of iterating through the whole list.\n",
    "\n",
    "corrected = values * corrections\n",
    "print('The corrected values are:', corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create multidimensional arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_correct = [[3.8, 0.8],[4.5,0.9],[6.2,0.95],[3.7,0.87],[5.2,0.6],[7.1,0.94]] #List of lists\n",
    "\n",
    "values_to_correct_array = np.array(values_to_correct)\n",
    "print(values_to_correct_array.shape) #This shows the dimensions of the array\n",
    "print(values_to_correct_array) #This shows a two dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To extract only the first row:\n",
    "print('The first row is:',values_to_correct_array[0])\n",
    "#To extract the first column:\n",
    "print('The first column is:', values_to_correct_array[:,0])\n",
    "#To extract element 3rd in row and 2nd in column:\n",
    "print('The element is:', values_to_correct_array[2,1]) #Remember that Python counts from 0!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy's file format\n",
    "\n",
    "When we need to store and read back a NumPy array, it is useful to know the functions `numpy.save` and `numpy.load`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/values_to_correct.npy', values_to_correct_array)\n",
    "test = np.load('data/values_to_correct.npy')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "NumPy offers many more options and as we cannot revise them all in this pre-course please check the documentation at [NumPy documentation](https://numpy.org/) to get more insights on it.\n",
    "\n",
    "## Reading files with NumPy\n",
    "\n",
    "One very important task that you will often face is to read text files containing data. NumPy offers options to do it. \n",
    "\n",
    "* When there are no missing values the simpler option is `numpy.loadtxt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's read a file containing lon, lat and slip for the 2010 Maule earthquake\n",
    "#lon, lat, slip = np.loadtxt('data/slip_maule.xyz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If there are missing values in the file we can use `numpy.genfromtxt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lon, lat, slip = np.genfromtxt('data/slip_maule.xyz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Pandas\n",
    "\n",
    "**DataFrames**, the data structure of Pandas, is very powerful. It is similar to NumPy arrays but it has the advantage of allowing different data types.\n",
    "\n",
    "* Creating a DataFrame from a **dictionary**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following dictionary contains the number of active volcanoes per region in 2019 in Italy\n",
    "volcanoes_italy = {'region': ['sicily', 'campania', 'lazio'],\n",
    "                   'active_volcanoes': [6, 2, 1]\n",
    "                  }                   \n",
    "print('The dict looks like:', volcanoes_italy)\n",
    "\n",
    "volcanoes_df = pd.DataFrame(volcanoes_italy)\n",
    "print('The DataFrame looks like:', volcanoes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can note, DataFrame looks much nicer, similar to a spreadsheet and easily readable. \n",
    "* Let's check how would look a DataFrame from a **list of lists** (`values_to_correct`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = [[38.14,73.41],[60.91,147.34],[3.30,95.98],[38.30,142.37],[52.62,159.78]]\n",
    "pandas_coord = pd.DataFrame(coordinates)\n",
    "print(pandas_coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to have a clearer data structure, we can also add names to the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_coord = pd.DataFrame(coordinates, columns = ['latitude','longitude'])\n",
    "print(pandas_coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DataFrame from a **NumPy array**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[9.5,38.14,73.41],[9.2,60.91,147.34],[9.1,3.30,95.98],[9.1,38.30,142.37],[9.0,52.62,159.78]])\n",
    "columns = ['magnitude', 'latitude', 'longitude']\n",
    "pd.DataFrame(data, columns=columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed, DataFrames always indicates an index, and to make it look better, it is also possible to **indicate a name to the index** column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['Valdivia1960', 'Alaska1964', 'Sumatra2004', 'Tohoku2011', 'Kamchatka1952']\n",
    "data_with_index = pd.DataFrame(data, columns=columns, index=index) \n",
    "data_with_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading files with Pandas\n",
    "\n",
    "A nice feature of Pandas is that can write and read Excel, CSV and other types of files. If we have a `.csv` file, we can easily read it with `pandas.read_csv()`. We just need to include the filename and the delimiter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ingv = pd.read_csv('data/ingv_seismic.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the following examples of what we can do using `read_csv`.\n",
    "\n",
    "* To visualize the first 5 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To visualize the last 5 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingv.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To check 3 random rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ingv.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can select certain columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ingv[['Station', 'Municipality']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use brackets, it tells pandas that we will select columns. And here we have used double brackets because we are giving a list of columns as argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To extract certain columns and certain rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ingv[['Municipality', 'Station']][1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The property `loc` is very useful to access a group of rows and columns by labels or boolean array. If we want to access the elements where the latitude is below 37, then we could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ingv.loc[ingv['Lat (N)'] < 37 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Or if we want to visualize only the information for a certain `Station`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingv.loc[ingv['Station'] == 'ISPIC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "* You learned about the main **differences** between Numpy and Pandas\n",
    "* You learned the **basics** of NumPy and Pandas\n",
    "* You learned to read files with Numpy using **`loadtxt`** and **`genfromtxt`**\n",
    "* You learned to read files with Pandas using **`read_csv`**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
